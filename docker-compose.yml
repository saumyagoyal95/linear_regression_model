version: '3.8'
# To rebuild images when Dockerfile or source code changes, use:
# docker compose up --build
services:
  linear-regression-backend:
    # image: linear_regression_image:v3
    build: 
      context: backend/
    ports:
      - "8000:8000"
    environment:
      - MODEL_REGISTRY_NAME=sklearn-lr-develop
      - MODEL_VERSION=2
      - MLFLOW_TRACKING_URI=http://mlflow:5550
      - MODEL_PATH=/code/app/model/linear_regression_model.pkl
    volumes:
        - /Users/saumyagoyal/JupyterNotebook/ML Engineering/linear_regression_model/training/pgdata:/var/lib/postgresql/data
    container_name: linear_regression_backend
    restart: unless-stopped

  frontend:
    build:
      context: frontend/
    ports:
      - "8501:8501"
    container_name: streamlit_frontend
    depends_on:
      - linear-regression-backend

######### mlflow service ######
  postgres:
      image: postgres:15
      container_name: mlflow-postgres-server
      environment:
        POSTGRES_USER: ${POSTGRES_USER}
        POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
        POSTGRES_DB: ${POSTGRES_DB}
      volumes:
        - /Users/saumyagoyal/JupyterNotebook/ML Engineering/linear_regression_model/training/pgdata:/var/lib/postgresql/data
      ports:
        - "5444:5432"
      healthcheck:
        test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
        interval: 5s
        timeout: 3s
        retries: 10

  mlflow:
      image: ghcr.io/mlflow/mlflow:${MLFLOW_VERSION}
      container_name: mlflow-server-1
      depends_on:
        postgres:
          condition: service_healthy
      environment:
        # Backend store URI built from vars
        MLFLOW_BACKEND_STORE_URI: ${MLFLOW_BACKEND_STORE_URI}
        # Server host/port
        MLFLOW_HOST: ${MLFLOW_HOST}
        MLFLOW_PORT: ${MLFLOW_PORT}
      volumes:
        - /Users/saumyagoyal/JupyterNotebook/ML Engineering/linear_regression_model/training/mlflow_artifacts:/mlartifacts
      command: >
        /bin/bash -c "
          pip install --no-cache-dir psycopg2-binary boto3 &&
          mlflow server \
            --backend-store-uri ${MLFLOW_BACKEND_STORE_URI} \
            --default-artifact-root ${MLFLOW_DEFAULT_ARTIFACT_ROOT} \
            --host ${MLFLOW_HOST} \
            --port ${MLFLOW_PORT}
        "
      ports:
        - "${MLFLOW_PORT}:${MLFLOW_PORT}"
      healthcheck:
        test:
          [
            "CMD",
            "python",
            "-c",
            "import urllib.request; urllib.request.urlopen('http://localhost:${MLFLOW_PORT}/health')",
          ]
        interval: 10s
        timeout: 5s
        retries: 30